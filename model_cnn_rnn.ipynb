{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/vicky/Downloads/NLSeer/NLSeer/finalized_df_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of          ACC                                       AnnotEncoded  \\\n",
      "0     O75439  3333333333333333333333333333333333333333333330...   \n",
      "1     Q2TBK2  3333333333333333333333333333333333333333333333...   \n",
      "2     Q5VY80  0000000000000000000000000000000000000000000000...   \n",
      "3     Q9BZM6  0000000000000000000000000000000000000000000000...   \n",
      "4     O75489  3333333333333333333333333333333333330000000000...   \n",
      "...      ...                                                ...   \n",
      "2947  Q96CK0  0000000000000000000000000000000000000000000000...   \n",
      "2948  Q96CK0  0000000000000000000000000000000000000000000000...   \n",
      "2949  Q24JY4  0000000000000000000000000000000000000066666666...   \n",
      "2950  O43257  0000000000000000000000000000000000000066666666...   \n",
      "2951  Q8R331  0000000000000000000000000000000000000066666666...   \n",
      "\n",
      "                                               Sequence Types  Length  \n",
      "0     MAAAAARVVLSSAARRRLWGFSESLLIRGAAGRSLYFGENRLRSTQ...    MT     489  \n",
      "1     MAAAAFAVPRGVQLRVLTERLLRGGVRELLRPRLSGSTPGSERDFS...    MT     268  \n",
      "2     MAAAAIPALLLCLPLLFLLFGWSRARRDDPHSLCYDITVIPKFRPG...   GPI     246  \n",
      "3     MAAAASPAFLLCLPLLHLLSGWSRAGWVDTHCLCYDFIITPKSRPE...   GPI     244  \n",
      "4     MAAAAVARLWWRGILGASALTRGTGRPSVLLLPVRRESAGADTRPT...    MT     264  \n",
      "...                                                 ...   ...     ...  \n",
      "2947  MAERALEPEAEAEAEAGAGGEAAAEEGAAGRKARGRPRLTESDRAR...   NLS     615  \n",
      "2948  MAERALEPEAEAEAEAGAGGEAAAEEGAAGRKARGRPRLTESDRAR...   NLS     615  \n",
      "2949  MVEKKTSVRSQDPGQRRVLDRAARQRRINRQLEALENDNFQDDPHA...   NLS     154  \n",
      "2950  MVEKKTSVRSQDPGQRRVLDRAARQRRINRQLEALENDNFQDDPHA...   NLS     154  \n",
      "2951  MVEKKPAVRSQDPGQRRVLDRAARQRRINRQLEALENDNFQDDPHA...   NLS     154  \n",
      "\n",
      "[2952 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_sequences(df, max_length):\n",
    "    char_set = {'A', 'C', 'G', 'T', 'D','E','F', 'H','I', 'K','L','M','N', 'P','Q', 'R','S','V','W','Y'}\n",
    "    char_to_int = {char: i for i, char in enumerate(char_set)}\n",
    "    sequences = []\n",
    "    for seq in df['Sequence']:\n",
    "        # Truncate or pad sequences\n",
    "        seq = seq[:max_length].ljust(max_length, '0')\n",
    "        # Convert to one-hot encoding\n",
    "        one_hot_seq = [char_to_int[char] for char in seq]\n",
    "        sequences.append(one_hot_seq)\n",
    "    return torch.tensor(sequences, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = {'A', 'C', 'D','E','F', 'G', 'H','I', 'K','L','M','N', 'P','Q', 'R','S', 'T','V','W','Y'}\n",
    "len(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = df['Sequence'][1]\n",
    "max_length = 1000\n",
    "seq = sequence[:max_length].ljust(max_length, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAAAAFAVPRGVQLRVLTERLLRGGVRELLRPRLSGSTPGSERDFSLSHSRGTVIVERWWKVPLAGEGRKPRLHRRHRVYKLVEDTKHRPKENLELILTQSVDELGVRGDLVSVKKSVGRNRLLPEGLAVYASPENKKLFEEEKLLRQEGKLDKIQTKAGEATVKFLRSCHLEVGMKNNVKWELNPEIVARHFLRNLGVVVAPHALKLPEEPITQRGEYWCEVTVNGLDTVRVPMSVVNFERPKTKRYKYWLAQQAAKGMASTSFQKI000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = df['Sequence']\n",
    "max_length = 1000\n",
    "# X = preprocess_sequences(df, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1))\n",
    "        output = self.fc(lstm_out.view(len(input_seq), -1))\n",
    "        output = self.sigmoid(output)\n",
    "        return output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the encoded data by Ming\n",
    "df_encoded = pd.read_csv(\"/home/vicky/Downloads/NLSeer/NLSeer/cnn_input_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[ -0.          -0.          -0.         ...  -0.          -0.\\n   -0.        ]\\n [-17.09913826  -0.          -0.         ...  -0.          -0.\\n   -0.        ]\\n [-12.31542206  -0.          -0.         ...  -0.          -0.\\n   -0.        ]\\n ...\\n [  0.           0.           0.         ...   0.           0.\\n    0.        ]\\n [  0.           0.           0.         ...   0.           0.\\n    0.        ]\\n [  0.           0.           0.         ...   0.           0.\\n    0.        ]]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded[\"Encoding\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Encoding  Label\n",
      "0     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "1     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
      "2     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "3     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "4     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
      "...                                                 ...    ...\n",
      "2709  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "2710  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "2711  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "2712  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "2713  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "\n",
      "[2714 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Using updated data by Ming\n",
    "import pickle\n",
    "\n",
    "# Specify the path to the pickled file\n",
    "file_path = '/home/vicky/Downloads/NLSeer/NLSeer/testing_data.pkl'\n",
    "\n",
    "# Open the pickled file in read mode\n",
    "with open(file_path, 'rb') as f:\n",
    "    # Load the pickled object\n",
    "    loaded_df = pickle.load(f)\n",
    "\n",
    "# Now you can use the loaded_object as needed\n",
    "print(loaded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_150286/616263396.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  X = torch.tensor(loaded_df[\"Encoding\"])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(loaded_df[\"Encoding\"])\n",
    "y = loaded_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2714, 1000, 20])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert Pandas DataFrame columns to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.tolist(), dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.tolist(), dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test.tolist(), dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.tolist(), dtype=torch.float)\n",
    "\n",
    "# Define DataLoader for train and test sets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2171, 1000, 20])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([1000, 20])\n",
      "y_batch shape: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_dataset:\n",
    "    print(\"X_batch shape:\", X_batch.shape)\n",
    "    print(\"y_batch shape:\", y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "max_length = 1000\n",
    "input_size = 20000  # Number of characters in the character set\n",
    "hidden_size = 128\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.5479\n",
      "Epoch [2/10], Loss: 0.2142\n",
      "Epoch [3/10], Loss: 0.0004\n",
      "Epoch [4/10], Loss: 0.0003\n",
      "Epoch [5/10], Loss: 0.0001\n",
      "Epoch [6/10], Loss: 0.0001\n",
      "Epoch [7/10], Loss: 0.0004\n",
      "Epoch [8/10], Loss: 0.0000\n",
      "Epoch [9/10], Loss: 0.0000\n",
      "Epoch [10/10], Loss: 0.0000\n",
      "Test Accuracy: 85.45%\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMModel(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_X, batch_y in train_dataloader:\n",
    "        # Move data to GPU\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_X)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_dataloader:\n",
    "        # Move data to GPU\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        output = model(batch_X)\n",
    "        test_loss += criterion(output, batch_y).item()\n",
    "        predicted = torch.round(output)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {(100 * correct / total):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ukamaka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
