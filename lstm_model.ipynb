{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/vicky/Downloads/NLSeer/NLSeer/finalized_df_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of          ACC                                       AnnotEncoded  \\\n",
      "0     O75439  3333333333333333333333333333333333333333333330...   \n",
      "1     Q2TBK2  3333333333333333333333333333333333333333333333...   \n",
      "2     Q5VY80  0000000000000000000000000000000000000000000000...   \n",
      "3     Q9BZM6  0000000000000000000000000000000000000000000000...   \n",
      "4     O75489  3333333333333333333333333333333333330000000000...   \n",
      "...      ...                                                ...   \n",
      "2947  Q96CK0  0000000000000000000000000000000000000000000000...   \n",
      "2948  Q96CK0  0000000000000000000000000000000000000000000000...   \n",
      "2949  Q24JY4  0000000000000000000000000000000000000066666666...   \n",
      "2950  O43257  0000000000000000000000000000000000000066666666...   \n",
      "2951  Q8R331  0000000000000000000000000000000000000066666666...   \n",
      "\n",
      "                                               Sequence Types  Length  \n",
      "0     MAAAAARVVLSSAARRRLWGFSESLLIRGAAGRSLYFGENRLRSTQ...    MT     489  \n",
      "1     MAAAAFAVPRGVQLRVLTERLLRGGVRELLRPRLSGSTPGSERDFS...    MT     268  \n",
      "2     MAAAAIPALLLCLPLLFLLFGWSRARRDDPHSLCYDITVIPKFRPG...   GPI     246  \n",
      "3     MAAAASPAFLLCLPLLHLLSGWSRAGWVDTHCLCYDFIITPKSRPE...   GPI     244  \n",
      "4     MAAAAVARLWWRGILGASALTRGTGRPSVLLLPVRRESAGADTRPT...    MT     264  \n",
      "...                                                 ...   ...     ...  \n",
      "2947  MAERALEPEAEAEAEAGAGGEAAAEEGAAGRKARGRPRLTESDRAR...   NLS     615  \n",
      "2948  MAERALEPEAEAEAEAGAGGEAAAEEGAAGRKARGRPRLTESDRAR...   NLS     615  \n",
      "2949  MVEKKTSVRSQDPGQRRVLDRAARQRRINRQLEALENDNFQDDPHA...   NLS     154  \n",
      "2950  MVEKKTSVRSQDPGQRRVLDRAARQRRINRQLEALENDNFQDDPHA...   NLS     154  \n",
      "2951  MVEKKPAVRSQDPGQRRVLDRAARQRRINRQLEALENDNFQDDPHA...   NLS     154  \n",
      "\n",
      "[2952 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = {'A', 'C', 'D','E','F', 'G', 'H','I', 'K','L','M','N', 'P','Q', 'R','S', 'T','V','W','Y'}\n",
    "len(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ACC                                           Encoding  Label\n",
      "0     O75439  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "1     Q2TBK2  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "2     Q5VY80  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "3     Q9BZM6  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "4     O75489  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "...      ...                                                ...    ...\n",
      "2947  Q96CK0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
      "2948  Q96CK0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
      "2949  Q24JY4  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
      "2950  O43257  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
      "2951  Q8R331  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
      "\n",
      "[2951 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Using Encoded data preprocessed by Ming\n",
    "import pickle\n",
    "\n",
    "# Specify the path to the pickled file\n",
    "file_path = '/home/vicky/Downloads/NLSeer/NLSeer/cnn_input_data.pkl' # for training \n",
    "file_path2 = '/home/vicky/Downloads/NLSeer/NLSeer/cnn_testing_data.pkl' # for testing\n",
    "# Open the pickled file in read mode\n",
    "with open(file_path, 'rb') as f:\n",
    "    # Load the pickled object\n",
    "    loaded_df = pickle.load(f)\n",
    "# the testing data\n",
    "with open(file_path2, 'rb') as g:\n",
    "    # Load the pickled object\n",
    "    test_df = pickle.load(g)\n",
    "\n",
    "# print the loaded_object\n",
    "print(loaded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Encoding  Label\n",
      "0     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "1     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
      "2     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "3     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "4     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
      "...                                                 ...    ...\n",
      "2709  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "2710  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "2711  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "2712  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "2713  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
      "\n",
      "[2714 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and the test set\n",
    "X_train = loaded_df[\"Encoding\"]\n",
    "y_train = loaded_df[\"Label\"]\n",
    "X_test = test_df[\"Encoding\"]\n",
    "y_test = test_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2171, 1000, 20])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173241/2145741785.py:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  X_train_tensor = torch.tensor(X_train.tolist(), dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert Pandas DataFrame columns to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.tolist(), dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.tolist(), dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test.tolist(), dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.tolist(), dtype=torch.float)\n",
    "\n",
    "# Define DataLoader for train and test sets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2951, 1000, 20])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([1000, 20])\n",
      "y_batch shape: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_dataset:\n",
    "    print(\"X_batch shape:\", X_batch.shape)\n",
    "    print(\"y_batch shape:\", y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1))\n",
    "        output = self.fc(lstm_out.view(len(input_seq), -1))\n",
    "        output = self.sigmoid(output)\n",
    "        return output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "max_length = 1000\n",
    "input_size = 20000  # Number of characters in the character set\n",
    "hidden_size = 200\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2167\n",
      "Epoch [2/10], Loss: 0.0546\n",
      "Epoch [3/10], Loss: 0.0001\n",
      "Epoch [4/10], Loss: 0.0002\n",
      "Epoch [5/10], Loss: 0.0000\n",
      "Epoch [6/10], Loss: 0.0000\n",
      "Epoch [7/10], Loss: 0.0000\n",
      "Epoch [8/10], Loss: 0.0112\n",
      "Epoch [9/10], Loss: 0.0000\n",
      "Epoch [10/10], Loss: 0.0009\n",
      "Test Accuracy: 85.45%\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMModel(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_X, batch_y in train_dataloader:\n",
    "        # Move data to GPU\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_X)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_dataloader:\n",
    "        # Move data to GPU\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        output = model(batch_X)\n",
    "        test_loss += criterion(output, batch_y).item()\n",
    "        predicted = torch.round(output)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {(100 * correct / total):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(20000, 200)\n",
       "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the main dataset into train and test data and fitting the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loaded_df[\"Encoding\"]\n",
    "y = loaded_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93120/3065182669.py:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  X_train_tensor = torch.tensor(X_train.tolist(), dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert Pandas DataFrame columns to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.tolist(), dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.tolist(), dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test.tolist(), dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.tolist(), dtype=torch.float)\n",
    "\n",
    "# Define DataLoader for train and test sets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1329\n",
      "Epoch [2/10], Loss: 0.0076\n",
      "Epoch [3/10], Loss: 0.0659\n",
      "Epoch [4/10], Loss: 0.0025\n",
      "Epoch [5/10], Loss: 0.0252\n",
      "Epoch [6/10], Loss: 0.0002\n",
      "Epoch [7/10], Loss: 0.0138\n",
      "Epoch [8/10], Loss: 0.0003\n",
      "Epoch [9/10], Loss: 0.0000\n",
      "Epoch [10/10], Loss: 0.0000\n",
      "Test Accuracy: 91.20%\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMModel(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_X, batch_y in train_dataloader:\n",
    "        # Move data to GPU\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_X)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_dataloader:\n",
    "        # Move data to GPU\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        output = model(batch_X)\n",
    "        test_loss += criterion(output, batch_y).item()\n",
    "        predicted = torch.round(output)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {(100 * correct / total):.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ukamaka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
