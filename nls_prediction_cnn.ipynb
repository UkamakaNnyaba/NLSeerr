{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### The architecture of the CNN used here is based on the paper \"[Extreme Gradient Boost with CNN: A Deep Learning-Based Approach for Predicting Protein Subcellular Localization](https://link.springer.com/chapter/10.1007/978-981-16-6636-0_16#Tab1)\" by Md. Ismail & Md. Nazrul Islam Mondal. We use modified one-hot encoded protein sequences as inputs."
      ],
      "metadata": {
        "id": "hb_leRzSQDOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this code on Google Colab\n",
        "!pip install xgboost\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check if the GPU is available and output its name\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2Nmk7yu26EX",
        "outputId": "ac43a704-9bc1-40eb-a2d7-a535dcfd58d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "Default GPU Device: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Confirm that GPU is being used\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZfTXptp3IcU",
        "outputId": "2cfc30fe-50df-4c4e-b9d4-5fb716de1e22"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The architecture is based on the paper mentioned in the title\n",
        "def build_cnn(input_shape):\n",
        "    # Input layer\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Convolutional layers with different kernel sizes\n",
        "    conv_layers = []\n",
        "    kernel_sizes = [1, 3, 5, 9, 15, 21]\n",
        "    for size in kernel_sizes:\n",
        "        conv = Conv1D(filters=64, kernel_size=size, activation='relu', padding='same')(inputs)\n",
        "        conv_layers.append(conv)\n",
        "\n",
        "    # Concatenate all convolutional layers\n",
        "    concatenated = concatenate(conv_layers, axis=-1)\n",
        "\n",
        "    # Final convolutional layer\n",
        "    final_conv = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(concatenated)\n",
        "\n",
        "    # Max pooling layer\n",
        "    pooled = MaxPooling1D(pool_size=5)(final_conv)\n",
        "\n",
        "    # Dropout layer\n",
        "    dropped = Dropout(rate=0.25)(pooled)\n",
        "\n",
        "    # Flatten layer\n",
        "    flatten = Flatten()(dropped)\n",
        "\n",
        "    # Dense layer\n",
        "    dense = Dense(64, activation='relu')(flatten)\n",
        "\n",
        "    # Output layer for binary classification\n",
        "    output = Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "epbJ29-74cT_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN2Zqp0P2EKL",
        "outputId": "54ec52a0-fbe0-4bb6-c9d0-22ec12615bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         ACC                                           Encoding  Label\n",
            "0     O75439  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "1     Q2TBK2  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "2     Q5VY80  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "3     Q9BZM6  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "4     O75489  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "...      ...                                                ...    ...\n",
            "2947  Q96CK0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "2948  Q96CK0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "2949  Q24JY4  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "2950  O43257  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "2951  Q8R331  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "\n",
            "[2951 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Loading the compressed pickle file that contained one-hot encoding modified with the pssm scores\n",
        "with gzip.open('cnn_input_data.pkl.gz', 'rb') as f:\n",
        "    df = pickle.load(f)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data\n",
        "X = np.stack(df['Encoding'].values)\n",
        "y = df['Label'].values.astype('int')  # Ensure labels are integers (0 or 1)\n",
        "\n",
        "# K-Fold Cross-Validation setup\n",
        "kf = KFold(n_splits=5, shuffle=True, ra ndom_state=50)\n",
        "fold = 0\n",
        "accuracies = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    fold += 1\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Build and compile CNN model\n",
        "    input_shape = (1000, 20)\n",
        "    cnn_model = build_cnn(input_shape)\n",
        "    cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "    # Train CNN model\n",
        "    history = cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "    # Extract features for XGBoost\n",
        "    feature_layer_model = Model(inputs=cnn_model.input, outputs=cnn_model.layers[-2].output)\n",
        "    X_train_features = feature_layer_model.predict(X_train)\n",
        "    X_test_features = feature_layer_model.predict(X_test)\n",
        "\n",
        "    # Train XGBoost on extracted features\n",
        "    xgb_model = xgb.XGBClassifier()\n",
        "    xgb_model.fit(X_train_features, y_train)\n",
        "\n",
        "    # Predict using XGBoost\n",
        "    y_pred_xgb = xgb_model.predict(X_test_features)\n",
        "\n",
        "    # Calculate and store accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "    accuracies.append(accuracy)\n",
        "    print(f\"Fold {fold}, Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "# Average accuracy across all folds\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(f\"Average Accuracy: {average_accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umEClQ0Y40a8",
        "outputId": "f652382f-b975-4190-810f-45142b86bf88"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "59/59 [==============================] - 5s 30ms/step - loss: 0.7509 - accuracy: 0.6822 - val_loss: 0.8076 - val_accuracy: 0.4407\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 1s 20ms/step - loss: 0.3581 - accuracy: 0.8284 - val_loss: 0.8823 - val_accuracy: 0.5678\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.1752 - accuracy: 0.9359 - val_loss: 0.5178 - val_accuracy: 0.7627\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.0806 - accuracy: 0.9778 - val_loss: 0.9896 - val_accuracy: 0.6674\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.0663 - accuracy: 0.9815 - val_loss: 0.9486 - val_accuracy: 0.6758\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0490 - accuracy: 0.9878 - val_loss: 1.0012 - val_accuracy: 0.6886\n",
            "74/74 [==============================] - 1s 5ms/step\n",
            "19/19 [==============================] - 0s 5ms/step\n",
            "Fold 1, Accuracy: 93.06%\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 5s 34ms/step - loss: 0.8626 - accuracy: 0.6340 - val_loss: 0.8350 - val_accuracy: 0.1691\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.4065 - accuracy: 0.7664 - val_loss: 0.7095 - val_accuracy: 0.6681\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.2828 - accuracy: 0.8914 - val_loss: 0.5987 - val_accuracy: 0.8118\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.1376 - accuracy: 0.9592 - val_loss: 0.5682 - val_accuracy: 0.8097\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.0905 - accuracy: 0.9740 - val_loss: 1.3003 - val_accuracy: 0.6195\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0682 - accuracy: 0.9809 - val_loss: 0.3656 - val_accuracy: 0.8858\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0513 - accuracy: 0.9857 - val_loss: 0.4107 - val_accuracy: 0.8584\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0689 - accuracy: 0.9788 - val_loss: 1.0248 - val_accuracy: 0.6956\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0534 - accuracy: 0.9836 - val_loss: 0.2984 - val_accuracy: 0.9429\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0490 - accuracy: 0.9852 - val_loss: 1.2297 - val_accuracy: 0.6913\n",
            "74/74 [==============================] - 1s 6ms/step\n",
            "19/19 [==============================] - 0s 17ms/step\n",
            "Fold 2, Accuracy: 91.02%\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 5s 28ms/step - loss: 0.7647 - accuracy: 0.7002 - val_loss: 0.9513 - val_accuracy: 0.2833\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.3540 - accuracy: 0.8438 - val_loss: 1.2001 - val_accuracy: 0.3488\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.1917 - accuracy: 0.9354 - val_loss: 0.4653 - val_accuracy: 0.8478\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.0832 - accuracy: 0.9735 - val_loss: 1.1725 - val_accuracy: 0.6068\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0762 - accuracy: 0.9746 - val_loss: 0.5436 - val_accuracy: 0.8140\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0629 - accuracy: 0.9799 - val_loss: 0.4564 - val_accuracy: 0.8414\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0434 - accuracy: 0.9878 - val_loss: 0.5649 - val_accuracy: 0.8372\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0382 - accuracy: 0.9873 - val_loss: 0.5975 - val_accuracy: 0.8309\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0350 - accuracy: 0.9915 - val_loss: 0.5803 - val_accuracy: 0.8309\n",
            "74/74 [==============================] - 1s 6ms/step\n",
            "19/19 [==============================] - 0s 7ms/step\n",
            "Fold 3, Accuracy: 90.85%\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 4s 26ms/step - loss: 1.1214 - accuracy: 0.6568 - val_loss: 0.8228 - val_accuracy: 0.3848\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.4472 - accuracy: 0.7579 - val_loss: 0.6343 - val_accuracy: 0.5835\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.3330 - accuracy: 0.8496 - val_loss: 0.6854 - val_accuracy: 0.6786\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.2077 - accuracy: 0.9258 - val_loss: 0.8177 - val_accuracy: 0.6554\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.1587 - accuracy: 0.9428 - val_loss: 0.8154 - val_accuracy: 0.6469\n",
            "74/74 [==============================] - 1s 6ms/step\n",
            "19/19 [==============================] - 0s 6ms/step\n",
            "Fold 4, Accuracy: 92.20%\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 4s 26ms/step - loss: 0.6268 - accuracy: 0.7378 - val_loss: 0.5470 - val_accuracy: 0.7188\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.1968 - accuracy: 0.9274 - val_loss: 0.4569 - val_accuracy: 0.8013\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0918 - accuracy: 0.9783 - val_loss: 0.9873 - val_accuracy: 0.5962\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0493 - accuracy: 0.9841 - val_loss: 0.3146 - val_accuracy: 0.8901\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0567 - accuracy: 0.9831 - val_loss: 0.6371 - val_accuracy: 0.7505\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 1s 20ms/step - loss: 0.0420 - accuracy: 0.9905 - val_loss: 0.6067 - val_accuracy: 0.7696\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 1s 21ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 0.3247 - val_accuracy: 0.8901\n",
            "74/74 [==============================] - 1s 5ms/step\n",
            "19/19 [==============================] - 0s 5ms/step\n",
            "Fold 5, Accuracy: 88.14%\n",
            "Average Accuracy: 91.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the testing data to do further prediction\n",
        "with gzip.open('cnn_testing_data.pkl.gz', 'rb') as f:\n",
        "    test_df = pickle.load(f)\n",
        "\n",
        "print(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqwlsFPAHYPt",
        "outputId": "f5f2d7de-36c5-402f-b0bf-109a6ad97c17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Encoding  Label\n",
            "0     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "1     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "2     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "3     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "4     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "...                                                 ...    ...\n",
            "2709  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "2710  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "2711  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "2712  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "2713  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "\n",
            "[2714 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict NLS on the testing set\n",
        "X_test = np.stack(test_df['Encoding'].values)\n",
        "y_test = test_df['Label'].values.astype('int')  # Ensure labels are integers (0 or 1)\n",
        "\n",
        "\n",
        "\n",
        "X_test_features = feature_layer_model.predict(X_test)\n",
        "\n",
        "\n",
        "# Predict using XGBoost\n",
        "y_pred_xgb = xgb_model.predict(X_test_features)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "print(f\"Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gue0ue2y2fNm",
        "outputId": "1b31a494-9216-4865-b06a-1da7366a13b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/85 [==============================] - 1s 9ms/step\n",
            "Accuracy: 73.58%\n"
          ]
        }
      ]
    }
  ]
}