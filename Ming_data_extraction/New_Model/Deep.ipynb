{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.ndimage\n",
    "try:\n",
    "    # PyTorch 1.7.0 and newer versions\n",
    "    import torch.fft\n",
    "\n",
    "    def dct1_rfft_impl(x):\n",
    "        return torch.view_as_real(torch.fft.rfft(x, dim=1))\n",
    "\n",
    "    def dct_fft_impl(v):\n",
    "        return torch.view_as_real(torch.fft.fft(v, dim=1))\n",
    "\n",
    "    def idct_irfft_impl(V):\n",
    "        return torch.fft.irfft(torch.view_as_complex(V), n=V.shape[1], dim=1)\n",
    "except ImportError:\n",
    "    # PyTorch 1.6.0 and older versions\n",
    "    def dct1_rfft_impl(x):\n",
    "        return torch.rfft(x, 1)\n",
    "\n",
    "    def dct_fft_impl(v):\n",
    "        return torch.rfft(v, 1, onesided=False)\n",
    "\n",
    "    def idct_irfft_impl(V):\n",
    "        return torch.irfft(V, 1, onesided=False)\n",
    "        \n",
    "def dct(x, norm=None):\n",
    "    \"\"\"\n",
    "    Discrete Cosine Transform, Type II (a.k.a. the DCT)\n",
    "    For the meaning of the parameter `norm`, see:\n",
    "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
    "    :param x: the input signal\n",
    "    :param norm: the normalization, None or 'ortho'\n",
    "    :return: the DCT-II of the signal over the last dimension\n",
    "    \"\"\"\n",
    "    x_shape = x.shape\n",
    "    N = x_shape[-1]\n",
    "    x = x.contiguous().view(-1, N)\n",
    "\n",
    "    v = torch.cat([x[:, ::2], x[:, 1::2].flip([1])], dim=1)\n",
    "\n",
    "    Vc = dct_fft_impl(v)\n",
    "\n",
    "    k = - torch.arange(N, dtype=x.dtype, device=x.device)[None, :] * np.pi / (2 * N)\n",
    "    W_r = torch.cos(k)\n",
    "    W_i = torch.sin(k)\n",
    "\n",
    "    V = Vc[:, :, 0] * W_r - Vc[:, :, 1] * W_i\n",
    "\n",
    "    if norm == 'ortho':\n",
    "        V[:, 0] /= np.sqrt(N) * 2\n",
    "        V[:, 1:] /= np.sqrt(N / 2) * 2\n",
    "\n",
    "    V = 2 * V.view(*x_shape)\n",
    "\n",
    "    return V\n",
    "\n",
    "\n",
    "def idct(X, norm=None):\n",
    "    \"\"\"\n",
    "    The inverse to DCT-II, which is a scaled Discrete Cosine Transform, Type III\n",
    "    Our definition of idct is that idct(dct(x)) == x\n",
    "    For the meaning of the parameter `norm`, see:\n",
    "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
    "    :param X: the input signal\n",
    "    :param norm: the normalization, None or 'ortho'\n",
    "    :return: the inverse DCT-II of the signal over the last dimension\n",
    "    \"\"\"\n",
    "\n",
    "    x_shape = X.shape\n",
    "    N = x_shape[-1]\n",
    "\n",
    "    X_v = X.contiguous().view(-1, x_shape[-1]) / 2\n",
    "\n",
    "    if norm == 'ortho':\n",
    "        X_v[:, 0] *= np.sqrt(N) * 2\n",
    "        X_v[:, 1:] *= np.sqrt(N / 2) * 2\n",
    "\n",
    "    k = torch.arange(x_shape[-1], dtype=X.dtype, device=X.device)[None, :] * np.pi / (2 * N)\n",
    "    W_r = torch.cos(k)\n",
    "    W_i = torch.sin(k)\n",
    "\n",
    "    V_t_r = X_v\n",
    "    V_t_i = torch.cat([X_v[:, :1] * 0, -X_v.flip([1])[:, :-1]], dim=1)\n",
    "\n",
    "    V_r = V_t_r * W_r - V_t_i * W_i\n",
    "    V_i = V_t_r * W_i + V_t_i * W_r\n",
    "\n",
    "    V = torch.cat([V_r.unsqueeze(2), V_i.unsqueeze(2)], dim=2)\n",
    "\n",
    "    v = idct_irfft_impl(V)\n",
    "    x = v.new_zeros(v.shape)\n",
    "    x[:, ::2] += v[:, :N - (N // 2)]\n",
    "    x[:, 1::2] += v.flip([1])[:, :N // 2]\n",
    "\n",
    "    return x.view(*x_shape)\n",
    "\n",
    "\n",
    "\n",
    "# Smoothing amount for gradients before computing attribution prior loss;\n",
    "# Smoothing window size is 1 + (2 * sigma); set to 0 for no smoothing\n",
    "att_prior_grad_smooth_sigma = 3\n",
    "\n",
    "# Maximum frequency integer to consider for a Fourier attribution prior\n",
    "fourier_att_prior_freq_limit = 100\n",
    "\n",
    "# Amount to soften the Fourier attribution prior loss limit; set to None\n",
    "# to not soften; softness decays like 1 / (1 + x^c) after the limit\n",
    "fourier_att_prior_freq_limit_softness = None\n",
    "def place_tensor(tensor, input_tensor):\n",
    "    \"\"\"\n",
    "    Places a tensor on GPU, if PyTorch sees CUDA; otherwise, the returned tensor\n",
    "    remains on CPU.\n",
    "    \"\"\"\n",
    "    return tensor.to(input_tensor.device)\n",
    "        \n",
    "def smooth_tensor_1d(input_tensor, smooth_sigma):\n",
    "    \"\"\"\n",
    "    Smooths an input tensor along a dimension using a Gaussian filter.\n",
    "    Arguments:\n",
    "        `input_tensor`: a A x B tensor to smooth along the second dimension\n",
    "        `smooth_sigma`: width of the Gaussian to use for smoothing; this is the\n",
    "            standard deviation of the Gaussian to use, and the Gaussian will be\n",
    "            truncated after 1 sigma (i.e. the smoothing window is\n",
    "            1 + (2 * sigma); sigma of 0 means no smoothing\n",
    "    Returns an array the same shape as the input tensor, with the dimension of\n",
    "    `B` smoothed.\n",
    "    \"\"\"\n",
    "    # Generate the kernel\n",
    "    if smooth_sigma == 0:\n",
    "        sigma, truncate = 1, 0\n",
    "    else:\n",
    "        sigma, truncate = smooth_sigma, 1\n",
    "    base = np.zeros(1 + (2 * sigma))\n",
    "    base[sigma] = 1  # Center of window is 1 everywhere else is 0\n",
    "    kernel = scipy.ndimage.gaussian_filter(base, sigma=sigma, truncate=truncate)\n",
    "    kernel = torch.tensor(kernel, dtype=torch.float32, device=input_tensor.device)\n",
    "\n",
    "    # Expand the input and kernel to 3D, with channels of 1\n",
    "    # Also make the kernel float-type, as the input is going to be of type float\n",
    "    input_tensor = torch.unsqueeze(input_tensor, dim=1)\n",
    "    kernel = torch.unsqueeze(torch.unsqueeze(kernel, dim=0), dim=1).float()\n",
    "    padded_input = F.pad(input_tensor, (sigma,sigma),\"replicate\")\n",
    "    smoothed = torch.nn.functional.conv1d(\n",
    "        padded_input, kernel\n",
    "    )\n",
    "    return torch.squeeze(smoothed, dim=1)\n",
    "\n",
    "\n",
    "def fourier_att_prior_loss_dct(\n",
    "        input_grads, freq_limit, limit_softness,\n",
    "        att_prior_grad_smooth_sigma\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Computes an attribution prior loss for some given training examples,\n",
    "    using a Fourier transform form.\n",
    "    Arguments:\n",
    "        `status`: a B-tensor, where B is the batch size; each entry is 1 if\n",
    "            that example is to be treated as a positive example, and 0\n",
    "            otherwise\n",
    "        `input_grads`: a B x L x D tensor, where B is the batch size, L is\n",
    "            the length of the input, and D is the dimensionality of each\n",
    "            input base; this needs to be the gradients of the input with\n",
    "            respect to the output (for multiple tasks, this gradient needs\n",
    "            to be aggregated); this should be *gradient times input*\n",
    "        `freq_limit`: the maximum integer frequency index, k, to consider for\n",
    "            the loss; this corresponds to a frequency cut-off of pi * k / L;\n",
    "            k should be less than L / 2\n",
    "        `limit_softness`: amount to soften the limit by, using a hill\n",
    "            function; None means no softness\n",
    "        `att_prior_grad_smooth_sigma`: amount to smooth the gradient before\n",
    "            computing the loss\n",
    "    Returns a single scalar Tensor consisting of the attribution loss for\n",
    "    the batch.\n",
    "    \"\"\"\n",
    "    abs_grads = torch.abs(input_grads)\n",
    "\n",
    "    # Smooth the gradients\n",
    "    grads_smooth = abs_grads \n",
    "    # smooth_tensor_1d(\n",
    "    #     abs_grads, att_prior_grad_smooth_sigma\n",
    "    # )\n",
    "\n",
    "    # Only do the positives\n",
    "    pos_grads = grads_smooth\n",
    "\n",
    "    # Loss for positives\n",
    "    if pos_grads.nelement():\n",
    "        #pos_fft = torch.rfft(pos_grads.float(), 1)\n",
    "        pos_dct = dct(pos_grads.float(), \"ortho\")\n",
    "        pos_mags = torch.abs(pos_dct)\n",
    "        pos_mag_sum = torch.sum(pos_mags, dim=1, keepdim=True)\n",
    "        pos_mag_sum[pos_mag_sum == 0] = 1  # Keep 0s when the sum is 0\n",
    "        pos_mags = pos_mags / pos_mag_sum\n",
    "\n",
    "        # Cut off DC\n",
    "        pos_mags = pos_mags[:, 1:]\n",
    "\n",
    "        # Construct weight vector\n",
    "        weights = place_tensor(torch.ones_like(pos_mags), input_grads)\n",
    "        if limit_softness is None:\n",
    "            weights[:, freq_limit:] = 0\n",
    "        else:\n",
    "            x = place_tensor(\n",
    "                torch.arange(1, pos_mags.size(1) - freq_limit + 1), input_grads\n",
    "            ).float()\n",
    "            weights[:, freq_limit:] = 1 / (1 + torch.pow(x, limit_softness))\n",
    "\n",
    "        # Multiply frequency magnitudes by weights\n",
    "        pos_weighted_mags = pos_mags * weights\n",
    "\n",
    "        # Add up along frequency axis to get score\n",
    "        pos_score = torch.sum(pos_weighted_mags, dim=1)\n",
    "        pos_loss = 1 - pos_score\n",
    "        return torch.mean(pos_loss)\n",
    "    else:\n",
    "        return place_tensor(torch.zeros(1), input_grads)\n",
    "\n",
    "\n",
    "def fourier_att_prior_loss(\n",
    "        input_grads, freq_limit, limit_softness,\n",
    "        att_prior_grad_smooth_sigma\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Computes an attribution prior loss for some given training examples,\n",
    "    using a Fourier transform form.\n",
    "    Arguments:\n",
    "        `status`: a B-tensor, where B is the batch size; each entry is 1 if\n",
    "            that example is to be treated as a positive example, and 0\n",
    "            otherwise\n",
    "        `input_grads`: a B x L x D tensor, where B is the batch size, L is\n",
    "            the length of the input, and D is the dimensionality of each\n",
    "            input base; this needs to be the gradients of the input with\n",
    "            respect to the output (for multiple tasks, this gradient needs\n",
    "            to be aggregated); this should be *gradient times input*\n",
    "        `freq_limit`: the maximum integer frequency index, k, to consider for\n",
    "            the loss; this corresponds to a frequency cut-off of pi * k / L;\n",
    "            k should be less than L / 2\n",
    "        `limit_softness`: amount to soften the limit by, using a hill\n",
    "            function; None means no softness\n",
    "        `att_prior_grad_smooth_sigma`: amount to smooth the gradient before\n",
    "            computing the loss\n",
    "    Returns a single scalar Tensor consisting of the attribution loss for\n",
    "    the batch.\n",
    "    \"\"\"\n",
    "    abs_grads = torch.abs(input_grads)\n",
    "\n",
    "    # Smooth the gradients\n",
    "    grads_smooth = abs_grads \n",
    "    # smooth_tensor_1d(\n",
    "    #     abs_grads, att_prior_grad_smooth_sigma\n",
    "    # )\n",
    "\n",
    "    # Only do the positives\n",
    "    pos_grads = grads_smooth\n",
    "\n",
    "    # Loss for positives\n",
    "    if pos_grads.nelement():\n",
    "        #pos_fft = torch.rfft(pos_grads.float(), 1)\n",
    "        pos_fft = torch.view_as_real(torch.fft.rfft(pos_grads.float()))\n",
    "        pos_mags = torch.norm(pos_fft, dim=2)\n",
    "        pos_mag_sum = torch.sum(pos_mags, dim=1, keepdim=True)\n",
    "        pos_mag_sum[pos_mag_sum == 0] = 1  # Keep 0s when the sum is 0\n",
    "        pos_mags = pos_mags / pos_mag_sum\n",
    "\n",
    "        # Cut off DC\n",
    "        pos_mags = pos_mags[:, 1:]\n",
    "\n",
    "        # Construct weight vector\n",
    "        weights = place_tensor(torch.ones_like(pos_mags))\n",
    "        if limit_softness is None:\n",
    "            weights[:, freq_limit:] = 0\n",
    "        else:\n",
    "            x = place_tensor(\n",
    "                torch.arange(1, pos_mags.size(1) - freq_limit + 1)\n",
    "            ).float()\n",
    "            weights[:, freq_limit:] = 1 / (1 + torch.pow(x, limit_softness))\n",
    "\n",
    "        # Multiply frequency magnitudes by weights\n",
    "        pos_weighted_mags = pos_mags * weights\n",
    "\n",
    "        # Add up along frequency axis to get score\n",
    "        pos_score = torch.sum(pos_weighted_mags, dim=1)\n",
    "        pos_loss = 1 - pos_score\n",
    "        return torch.mean(pos_loss)\n",
    "    else:\n",
    "        return place_tensor(torch.zeros(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CATEGORIES = [\"Membrane\",\"Cytoplasm\",\"Nucleus\",\"Extracellular\",\"Cell membrane\",\"Mitochondrion\",\"Plastid\",\"Endoplasmic reticulum\",\"Lysosome/Vacuole\",\"Golgi apparatus\",\"Peroxisome\"]\n",
    "SS_CATEGORIES = [\"NULL\", \"SP\", \"TM\", \"MT\", \"CH\", \"TH\", \"NLS\", \"NES\", \"PTS\", \"GPI\"] \n",
    "\n",
    "FAST = \"Fast\"\n",
    "ACCURATE = \"Accurate\"\n",
    "\n",
    "EMBEDDINGS = {\n",
    "    FAST: {\n",
    "        \"embeds\": \"data_files/embeddings/esm1b_swissprot.h5\",\n",
    "        \"config\": \"swissprot_esm1b.yaml\",\n",
    "        \"source_fasta\": \"data_files/deeploc_swissprot_clipped1k.fasta\"\n",
    "    },\n",
    "    ACCURATE: {\n",
    "        \"embeds\": \"data_files/embeddings/prott5_swissprot.h5\",\n",
    "        \"config\": \"swissprot_prott5.yaml\",\n",
    "        \"source_fasta\": \"data_files/deeploc_swissprot_clipped4k.fasta\"\n",
    "    }\n",
    "}\n",
    "\n",
    "SIGNAL_DATA = \"data_files/multisub_ninesignals.pkl\"\n",
    "LOCALIZATION_DATA = \"./data_files/multisub_5_partitions_unique.csv\"\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "SUP_LOSS_MULT = 0.1\n",
    "REG_LOSS_MULT = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "import pandas as pd\n",
    "import time \n",
    "import os\n",
    "class FastaBatchedDatasetTorch(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_df):\n",
    "        self.data_df = data_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def shuffle(self):\n",
    "        self.data_df = self.data_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_df[\"Sequence\"][idx], self.data_df[\"ACC\"][idx]\n",
    "\n",
    "    def get_batch_indices(self, toks_per_batch, extra_toks_per_seq=0):\n",
    "        sizes = [(len(s), i) for i, s in enumerate(self.data_df[\"Sequence\"])]\n",
    "        sizes.sort(reverse=True)\n",
    "        batches = []\n",
    "        buf = []\n",
    "        max_len = 0\n",
    "\n",
    "        def _flush_current_buf():\n",
    "            nonlocal max_len, buf\n",
    "            if len(buf) == 0:\n",
    "                return\n",
    "            batches.append(buf)\n",
    "            buf = []\n",
    "            max_len = 0\n",
    "        start = 0\n",
    "        #start = random.randint(0, len(sizes))\n",
    "        for j in range(len(sizes)):\n",
    "            i = (start + j) % len(sizes)\n",
    "            sz = sizes[i][0]\n",
    "            idx = sizes[i][1]    \n",
    "            sz += extra_toks_per_seq\n",
    "            if (max(sz, max_len) * (len(buf) + 1) > toks_per_batch):\n",
    "                _flush_current_buf()\n",
    "            max_len = max(max_len, sz)\n",
    "            buf.append(idx)\n",
    "\n",
    "        _flush_current_buf()\n",
    "        return batches\n",
    "\n",
    "class BatchConverterProtT5(object):\n",
    "    \"\"\"Callable to convert an unprocessed (labels + strings) batch to a\n",
    "    processed (labels + tensor) batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alphabet):\n",
    "        self.alphabet = alphabet\n",
    "\n",
    "    def __call__(self, raw_batch):\n",
    "        # RoBERTa uses an eos token, while ESM-1 does not.\n",
    "        batch_size = len(raw_batch)\n",
    "        #print(len(raw_batch[0]), raw_batch[1], raw_batch[2])\n",
    "        max_len = max(len(seq_str) for seq_str, _ in raw_batch)\n",
    "        labels = []\n",
    "        lengths = []\n",
    "        strs = []\n",
    "        for i, (seq_str, label) in enumerate(raw_batch):\n",
    "            #seq_str = seq_str[1:]\n",
    "            labels.append(label)\n",
    "            lengths.append(len(seq_str))\n",
    "            strs.append(seq_str)\n",
    "        \n",
    "        proteins = [\" \".join(list(item)) for item in strs]\n",
    "        proteins = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in proteins]\n",
    "        ids = self.alphabet.batch_encode_plus(proteins, add_special_tokens=True, padding=True)\n",
    "        non_pad_mask = torch.tensor(ids['input_ids']) > -100 # B, T\n",
    "\n",
    "        return ids, torch.tensor(lengths), non_pad_mask, labels\n",
    "\n",
    "\n",
    "class BatchConverter(object):\n",
    "    \"\"\"Callable to convert an unprocessed (labels + strings) batch to a\n",
    "    processed (labels + tensor) batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alphabet):\n",
    "        self.alphabet = alphabet\n",
    "\n",
    "    def __call__(self, raw_batch):\n",
    "        # RoBERTa uses an eos token, while ESM-1 does not.\n",
    "        batch_size = len(raw_batch)\n",
    "        #print(len(raw_batch[0]), raw_batch[1], raw_batch[2])\n",
    "        max_len = max(len(seq_str) for seq_str, _ in raw_batch)\n",
    "        tokens = torch.empty((batch_size, max_len + int(self.alphabet.prepend_bos) + \\\n",
    "            int(self.alphabet.append_eos)), dtype=torch.int64)\n",
    "        tokens.fill_(self.alphabet.padding_idx)\n",
    "        labels = []\n",
    "        lengths = []\n",
    "        strs = []\n",
    "        for i, (seq_str, label) in enumerate(raw_batch):\n",
    "            #seq_str = seq_str[1:]\n",
    "            labels.append(label)\n",
    "            lengths.append(len(seq_str))\n",
    "            strs.append(seq_str)\n",
    "            if self.alphabet.prepend_bos:\n",
    "                tokens[i, 0] = self.alphabet.cls_idx\n",
    "            seq = torch.tensor([self.alphabet.get_idx(s) for s in seq_str], dtype=torch.int64)\n",
    "            tokens[i, int(self.alphabet.prepend_bos) : len(seq_str) + int(self.alphabet.prepend_bos)] = seq\n",
    "            if self.alphabet.append_eos:\n",
    "                tokens[i, len(seq_str) + int(self.alphabet.prepend_bos)] = self.alphabet.eos_idx\n",
    "        \n",
    "        non_pad_mask = ~tokens.eq(self.alphabet.padding_idx) &\\\n",
    "         ~tokens.eq(self.alphabet.cls_idx) &\\\n",
    "         ~tokens.eq(self.alphabet.eos_idx)# B, T\n",
    "\n",
    "        return tokens, torch.tensor(lengths), non_pad_mask, labels\n",
    "\n",
    "def read_fasta(fastafile):\n",
    "    \"\"\"Parse a file with sequences in FASTA format and store in a dict\"\"\"\n",
    "    proteins = list(SeqIO.parse(fastafile, \"fasta\"))\n",
    "    res = {}\n",
    "    for prot in proteins:\n",
    "        res[str(prot.id)] = str(prot.seq)\n",
    "    return res\n",
    "\n",
    "# with open(\"/tools/src/deeploc-2.0/models/ESM1b_alphabet.pkl\", \"rb\") as f:\n",
    "#     alphabet = pickle.load(f)\n",
    "\n",
    "###################################\n",
    "#######   TRAINING STUFF  #########\n",
    "###################################\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pickle5\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from src.constants import *\n",
    "\n",
    "def get_swissprot_df(clip_len):  \n",
    "    with open(SIGNAL_DATA, \"rb\") as f:\n",
    "        annot_df = pickle5.load(f)\n",
    "    nes_exclude_list = ['Q7TPV4','P47973','P38398','P38861','Q16665','O15392','Q9Y8G3','O14746','P13350','Q06142']\n",
    "    swissprot_exclusion_list = ['Q04656-5','O43157','Q9UPN3-2']\n",
    "    def clip_middle_np(x):\n",
    "        if len(x)>clip_len:\n",
    "            x = np.concatenate((x[:clip_len//2],x[-clip_len//2:]), axis=0)\n",
    "        return x\n",
    "    def clip_middle(x):\n",
    "      if len(x)>clip_len:\n",
    "          x = x[:clip_len//2] + x[-clip_len//2:]\n",
    "      return x\n",
    " \n",
    "    annot_df[\"TargetAnnot\"] = annot_df[\"ANNOT\"].apply(lambda x: clip_middle_np(x))\n",
    "    data_df = pd.read_csv(LOCALIZATION_DATA)\n",
    "    data_df[\"Sequence\"] = data_df[\"Sequence\"].apply(lambda x: clip_middle(x))\n",
    "    data_df[\"Target\"] = data_df[CATEGORIES].values.tolist()    \n",
    "\n",
    "    annot_df = annot_df[~annot_df.ACC.isin(nes_exclude_list)].reset_index(drop=True)\n",
    "    data_df = data_df[~data_df.ACC.isin(swissprot_exclusion_list)].reset_index(drop=True)\n",
    "    data_df = data_df.merge(annot_df[[\"ACC\", \"ANNOT\", \"Types\", \"TargetAnnot\"]], on=\"ACC\", how=\"left\")\n",
    "    data_df['TargetAnnot'] = data_df['TargetAnnot'].fillna(0)\n",
    "\n",
    "    # embedding_fasta = read_fasta(f\"{embedding_path}/remapped_sequences_file.fasta\")\n",
    "    # embedding_df = pd.DataFrame(embedding_fasta.items(), columns=[\"details\", \"RawSeq\"])\n",
    "    # embedding_df[\"Hash\"] = embedding_df.details.apply(lambda x: x.split()[0])\n",
    "    # embedding_df[\"ACC\"] = embedding_df.details.apply(lambda x: x.split()[1])\n",
    "    # data_df = data_df.merge(embedding_df[[\"ACC\", \"Hash\"]]).reset_index(drop=True)\n",
    "\n",
    "    return data_df\n",
    "\n",
    "def convert_to_binary(x):\n",
    "    types_binary = np.zeros((len(SS_CATEGORIES)-1,))\n",
    "    for c in x.split(\"_\"):\n",
    "      types_binary[SS_CATEGORIES.index(c)-1] = 1\n",
    "    return types_binary\n",
    "\n",
    "def get_swissprot_ss_Xy(save_path, fold, clip_len):\n",
    "    with open(SIGNAL_DATA, \"rb\") as f:\n",
    "        annot_df = pickle5.load(f)\n",
    "    nes_exclude_list = ['Q7TPV4','P47973','P38398','P38861','Q16665','O15392','Q9Y8G3','O14746','P13350','Q06142']\n",
    "    swissprot_exclusion_list = ['Q04656-5','O43157','Q9UPN3-2']\n",
    "    def clip_middle_np(x):\n",
    "        if len(x)>clip_len:\n",
    "            x = np.concatenate((x[:clip_len//2],x[-clip_len//2:]), axis=0)\n",
    "        return x\n",
    "    def clip_middle(x):\n",
    "      if len(x)>clip_len:\n",
    "          x = x[:clip_len//2] + x[-clip_len//2:]\n",
    "      return x\n",
    "    \n",
    "    train_annot_pred_df = pd.read_pickle(os.path.join(save_path, f\"inner_{fold}_1Layer.pkl\"))\n",
    "    test_annot_pred_df = pd.read_pickle(os.path.join(save_path, f\"{fold}_1Layer.pkl\"))\n",
    "    assert train_annot_pred_df.merge(test_annot_pred_df, on=\"ACC\").empty == True\n",
    "\n",
    "    \n",
    "    filt_annot_df = annot_df[annot_df[\"Types\"]!=\"\"].reset_index(drop=True)\n",
    "    seq_df = filt_annot_df.merge(train_annot_pred_df)\n",
    "    seq_df[\"Sequence\"] = seq_df[\"Sequence\"].apply(lambda x: clip_middle(x))\n",
    "    seq_df[\"Target\"] = seq_df[CATEGORIES].values.tolist()\n",
    "    seq_df[\"TargetSignal\"] = seq_df[\"Types\"].apply(lambda x: convert_to_binary(x))\n",
    "\n",
    "    annot_true_df = seq_df\n",
    "    X_true_train, y_true_train = np.concatenate((np.stack(annot_true_df[\"embeds\"].to_numpy()), np.stack(annot_true_df[\"Target\"].to_numpy())), axis=1) , np.stack(annot_true_df[\"TargetSignal\"].to_numpy())\n",
    "    annot_pred_df = seq_df\n",
    "    X_pred_target = np.stack(annot_true_df[\"preds\"].to_numpy())# > threshold_dict[f\"{i}_multidct\"]\n",
    "    X_pred_train, y_pred_train = np.concatenate((np.stack(annot_pred_df[\"embeds\"].to_numpy()), X_pred_target), axis=1), np.stack(annot_pred_df[\"TargetSignal\"].to_numpy())\n",
    "\n",
    "    seq_df = filt_annot_df.merge(test_annot_pred_df)\n",
    "    seq_df[\"Sequence\"] = seq_df[\"Sequence\"].apply(lambda x: clip_middle(x))\n",
    "    seq_df[\"Target\"] = seq_df[CATEGORIES].values.tolist()\n",
    "    seq_df[\"TargetSignal\"] = seq_df[\"Types\"].apply(lambda x: convert_to_binary(x))\n",
    "\n",
    "    annot_test_df = seq_df\n",
    "    X_test_target = np.stack(annot_test_df[\"preds\"].to_numpy())# > threshold_dict[f\"{i}_multidct\"]\n",
    "    X_test, y_test = np.concatenate((np.stack(annot_test_df[\"embeds\"].to_numpy()), X_test_target), axis=1), np.stack(annot_test_df[\"TargetSignal\"].to_numpy())\n",
    "    \n",
    "    X_train = np.concatenate((X_true_train, X_pred_train), axis=0)\n",
    "    y_train = np.concatenate((y_true_train, y_pred_train), axis=0)\n",
    "    #print(X_train.shape, X_test.shape)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "class EmbeddingsLocalizationDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset of protein embeddings and the corresponding subcellular localization label.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_file, data_df) -> None:\n",
    "        super().__init__()\n",
    "        self.data_df = data_df\n",
    "        self.embeddings_file = embedding_file\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        embedding = np.array(self.embeddings_file[self.data_df[\"ACC\"][index]]).copy()\n",
    "        return self.data_df[\"Sequence\"][index], embedding, self.data_df[\"Target\"][index], self.data_df[\"TargetAnnot\"][index], self.data_df[\"ACC\"][index]\n",
    "    \n",
    "    def get_batch_indices(self, toks_per_batch, max_batch_size, extra_toks_per_seq=0):\n",
    "        sizes = [(len(s), i) for i, s in enumerate(self.data_df[\"Sequence\"])]\n",
    "        sizes.sort(reverse=True)\n",
    "        batches = []\n",
    "        buf = []\n",
    "        max_len = 0\n",
    "\n",
    "        def _flush_current_buf():\n",
    "            nonlocal max_len, buf\n",
    "            if len(buf) == 0:\n",
    "                return\n",
    "            batches.append(buf)\n",
    "            buf = []\n",
    "            max_len = 0\n",
    "        start = 0\n",
    "        #start = random.randint(0, len(sizes))\n",
    "        for j in range(len(sizes)):\n",
    "            i = (start + j) % len(sizes)\n",
    "            sz = sizes[i][0]\n",
    "            idx = sizes[i][1]    \n",
    "            sz += extra_toks_per_seq\n",
    "            if (max(sz, max_len) * (len(buf) + 1) > toks_per_batch) or len(buf) >= max_batch_size:\n",
    "                _flush_current_buf()\n",
    "            max_len = max(max_len, sz)\n",
    "            buf.append(idx)\n",
    "\n",
    "        _flush_current_buf()\n",
    "        return batches\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_df)\n",
    "\n",
    "class TrainBatchConverter(object):\n",
    "    \"\"\"Callable to convert an unprocessed (labels + strings) batch to a\n",
    "    processed (labels + tensor) batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alphabet, embed_len):\n",
    "        self.alphabet = alphabet\n",
    "        self.embed_len = embed_len\n",
    "\n",
    "    def __call__(self, raw_batch):\n",
    "        batch_size = len(raw_batch)\n",
    "        max_len = max(len(seq_str) for seq_str, _, _, _, _ in raw_batch)\n",
    "        embedding_tensor = torch.zeros((batch_size, max_len, self.embed_len), dtype=torch.float32)\n",
    "        np_mask = torch.zeros((batch_size, max_len))\n",
    "        target_annots = torch.zeros((batch_size, max_len), dtype=torch.int64)\n",
    "        labels = []\n",
    "        lengths = []\n",
    "        strs = []\n",
    "        targets = torch.zeros((batch_size, 11), dtype=torch.float32)\n",
    "        for i, (seq_str, embedding, target, target_annot, label) in enumerate(raw_batch):\n",
    "            #seq_str = seq_str[1:]\n",
    "            labels.append(label)\n",
    "            lengths.append(len(seq_str))\n",
    "            strs.append(seq_str)\n",
    "            targets[i] = torch.tensor(target)\n",
    "            embedding_tensor[i, :len(seq_str)] = torch.tensor(np.array(embedding))\n",
    "            target_annots[i, :len(seq_str)] = torch.tensor(target_annot)\n",
    "            np_mask[i, :len(seq_str)] = 1\n",
    "        np_mask = np_mask == 1\n",
    "        return embedding_tensor, torch.tensor(lengths), np_mask, targets, target_annots, labels\n",
    "    \n",
    "class SignalTypeDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y) -> None:\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        return torch.tensor(self.X[index]).float(), torch.tensor(self.y[index]).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "\n",
    "class DataloaderHandler:\n",
    "    def __init__(self, clip_len, alphabet, embedding_file, embed_len) -> None:\n",
    "        self.clip_len = clip_len\n",
    "        self.alphabet = alphabet\n",
    "        self.embedding_file = embedding_file\n",
    "        self.embed_len = embed_len\n",
    "\n",
    "    def get_train_val_dataloaders(self, outer_i):\n",
    "        data_df = get_swissprot_df(self.clip_len)\n",
    "        \n",
    "        train_df = data_df[data_df.Partition != outer_i].reset_index(drop=True)\n",
    "\n",
    "        X = np.stack(train_df[\"ACC\"].to_numpy())\n",
    "        sss_tt = ShuffleSplit(n_splits=1, test_size=2048, random_state=0)\n",
    "        \n",
    "        (split_train_idx, split_val_idx) = next(sss_tt.split(X))\n",
    "        split_train_df =  train_df.iloc[split_train_idx].reset_index(drop=True)\n",
    "        split_val_df = train_df.iloc[split_val_idx].reset_index(drop=True)\n",
    "\n",
    "        # print(split_train_df[CATEGORIES].mean())\n",
    "        # print(split_val_df[CATEGORIES].mean())\n",
    "        embedding_file = h5py.File(self.embedding_file, \"r\")\n",
    "        train_dataset = EmbeddingsLocalizationDataset(embedding_file, split_train_df)\n",
    "        train_batches = train_dataset.get_batch_indices(4096*4, BATCH_SIZE, extra_toks_per_seq=0)\n",
    "        train_dataloader = torch.utils.data.DataLoader(train_dataset, collate_fn=TrainBatchConverter(self.alphabet, self.embed_len), batch_sampler=train_batches)\n",
    "\n",
    "        val_dataset = EmbeddingsLocalizationDataset(embedding_file, split_val_df)\n",
    "        val_batches = val_dataset.get_batch_indices(4096*4, BATCH_SIZE, extra_toks_per_seq=0)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, collate_fn=TrainBatchConverter(self.alphabet, self.embed_len), batch_sampler=val_batches)\n",
    "        return train_dataloader, val_dataloader\n",
    "\n",
    "    def get_partition(self, outer_i):\n",
    "        data_df = get_swissprot_df(self.clip_len )\n",
    "        test_df = data_df[data_df.Partition == outer_i].reset_index(drop=True)\n",
    "        return test_df\n",
    "\n",
    "    def get_partition_dataloader(self, outer_i):\n",
    "        data_df = get_swissprot_df(self.clip_len)\n",
    "        test_df = data_df[data_df.Partition == outer_i].reset_index(drop=True)\n",
    "        \n",
    "        embedding_file = h5py.File(self.embedding_file, \"r\")\n",
    "        test_dataset = EmbeddingsLocalizationDataset(embedding_file, test_df)\n",
    "        test_batches = test_dataset.get_batch_indices(4096*4, BATCH_SIZE, extra_toks_per_seq=0)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, collate_fn=TrainBatchConverter(self.alphabet, self.embed_len), batch_sampler=test_batches)\n",
    "        return test_dataloader, test_df\n",
    "\n",
    "    def get_partition_dataloader_inner(self, partition_i):\n",
    "        data_df = get_swissprot_df(self.clip_len)\n",
    "        test_df = data_df[data_df.Partition != partition_i].reset_index(drop=True)\n",
    "        embedding_file = h5py.File(self.embedding_file, \"r\")\n",
    "        test_dataset = EmbeddingsLocalizationDataset(embedding_file, test_df)\n",
    "        test_batches = test_dataset.get_batch_indices(4096*4, BATCH_SIZE, extra_toks_per_seq=0)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, collate_fn=TrainBatchConverter(self.alphabet, self.embed_len), batch_sampler=test_batches)\n",
    "\n",
    "        return test_dataloader, test_df\n",
    "    \n",
    "    def get_ss_train_val_dataloader(self, save_path, outer_i):\n",
    "        X, y, _, _ = get_swissprot_ss_Xy(save_path, outer_i, clip_len=self.clip_len)\n",
    "        sss_tt = ShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "        \n",
    "        (split_train_idx, split_val_idx) = next(sss_tt.split(y))\n",
    "        split_train_X, split_train_y =  X[split_train_idx], y[split_train_idx]\n",
    "        split_val_X, split_val_y = X[split_val_idx], y[split_val_idx]\n",
    "\n",
    "        print(split_train_X.shape, split_train_y.shape, split_val_X.shape, split_val_y.shape)\n",
    "        \n",
    "        train_dataset = SignalTypeDataset(split_train_X, split_train_y)\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            shuffle=True,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            drop_last=True)\n",
    "\n",
    "        val_dataset = SignalTypeDataset(split_val_X, split_val_y)\n",
    "        val_dataloader = torch.utils.data.DataLoader(\n",
    "            val_dataset,\n",
    "            shuffle=False,\n",
    "            batch_size=BATCH_SIZE)\n",
    "        \n",
    "        return train_dataloader, val_dataloader\n",
    "\n",
    "    def get_ss_test_dataloader(self, save_path, outer_i):\n",
    "        _, _, X, y = get_swissprot_ss_Xy(save_path, outer_i, clip_len=self.clip_len)\n",
    "        \n",
    "        print(X.shape, y.shape)\n",
    "        val_dataset = SignalTypeDataset(X, y)\n",
    "        val_dataloader = torch.utils.data.DataLoader(\n",
    "            val_dataset,\n",
    "            shuffle=False,\n",
    "            batch_size=X.shape[0])\n",
    "\n",
    "        return val_dataloader\n",
    "    \n",
    "    def get_swissprot_ss_xy(self, save_path, outer_i):\n",
    "        return get_swissprot_ss_Xy(save_path=save_path, fold=outer_i, clip_len=self.clip_len)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "from esm import Alphabet, FastaBatchedDataset, pretrained\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "import tqdm\n",
    "from src.data import *\n",
    "from src.utils import *\n",
    "import os\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    dtype = torch.float16\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"cpu\"\n",
    "    dtype=torch.bfloat16\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    dtype=torch.bfloat16\n",
    "\n",
    "def embed_esm1b(embed_dataloader, out_file):\n",
    "    model, _ = pretrained.load_model_and_alphabet(\"esm1b_t33_650M_UR50S\")\n",
    "    model.eval().to(device)\n",
    "    embed_h5 = h5py.File(out_file, \"w\")\n",
    "    try:\n",
    "        with torch.autocast(device_type=device,dtype=dtype):\n",
    "            with torch.no_grad():\n",
    "                for i, (toks, lengths, np_mask, labels) in tqdm.tqdm(enumerate(embed_dataloader)):\n",
    "                    embed = model(toks.to(device), repr_layers=[33])[\"representations\"][33].float().cpu().numpy()\n",
    "                    for j in range(len(labels)):\n",
    "                        # removing start and end tokens\n",
    "                        embed_h5[labels[j]] = embed[j, 1:1+lengths[j]].astype(np.float16)\n",
    "        embed_h5.close()\n",
    "    except:\n",
    "        os.system(f\"rm {out_file}\")\n",
    "        raise Exception(\"Failed to create embeddings\")\n",
    "    \n",
    "\n",
    "def embed_prott5(embed_dataloader, out_file):\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\")\n",
    "    model.eval().to(device)\n",
    "    embed_h5 = h5py.File(out_file, \"w\")\n",
    "    try:\n",
    "        with torch.autocast(device_type=device,dtype=dtype):\n",
    "            with torch.no_grad():\n",
    "                for i, (toks, lengths, np_mask, labels) in tqdm.tqdm(enumerate(embed_dataloader)):\n",
    "                    embed = model(input_ids=torch.tensor(toks['input_ids'], device=device),\n",
    "                    attention_mask=torch.tensor(toks['attention_mask'], \n",
    "                        device=device)).last_hidden_state.float().cpu().numpy()\n",
    "                    for j in range(len(labels)):\n",
    "                        # removing end tokens\n",
    "                        embed_h5[labels[j]] = embed[j, :lengths[j]].astype(np.float16)\n",
    "        embed_h5.close()\n",
    "    except:\n",
    "        os.system(f\"rm {out_file}\")\n",
    "        raise Exception(\"Failed to create embeddings\")\n",
    "\n",
    "def generate_embeddings(model_attrs: ModelAttributes):\n",
    "    fasta_dict = read_fasta(EMBEDDINGS[model_attrs.model_type][\"source_fasta\"])\n",
    "    test_df = pd.DataFrame(fasta_dict.items(), columns=['ACC', 'Sequence'])\n",
    "    embed_dataset = FastaBatchedDatasetTorch(test_df)\n",
    "    embed_batches = embed_dataset.get_batch_indices(8196, extra_toks_per_seq=1)\n",
    "    if model_attrs.model_type == FAST:\n",
    "        embed_dataloader = torch.utils.data.DataLoader(embed_dataset, collate_fn=BatchConverter(model_attrs.alphabet), batch_sampler=embed_batches)\n",
    "        embed_esm1b(embed_dataloader, EMBEDDINGS[model_attrs.model_type][\"embeds\"])\n",
    "    elif model_attrs.model_type == ACCURATE:\n",
    "        embed_dataloader = torch.utils.data.DataLoader(embed_dataset, collate_fn=BatchConverterProtT5(model_attrs.alphabet), batch_sampler=embed_batches)\n",
    "        embed_prott5(embed_dataloader, EMBEDDINGS[model_attrs.model_type][\"embeds\"])\n",
    "    else:\n",
    "        raise Exception(\"wrong model type provided expected Fast,Accurate got\", model_attrs.model_type)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from src.utils import ModelAttributes\n",
    "from src.data import DataloaderHandler\n",
    "from src.metrics import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    dtype = torch.float16\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"cpu\"\n",
    "    dtype=torch.bfloat16\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    dtype=torch.bfloat16\n",
    "\n",
    "def predict_sl_values(dataloader, model):\n",
    "    output_dict = {}\n",
    "    annot_dict = {}\n",
    "    pool_dict = {}\n",
    "    with torch.no_grad():\n",
    "      for i, (toks, lengths, np_mask, targets, targets_seq, labels) in tqdm.tqdm(enumerate(dataloader)):\n",
    "        with torch.autocast(device_type=device,dtype=dtype):\n",
    "            y_pred, y_pool, y_attn = model.predict(toks.to(device), lengths.to(device), np_mask.to(device))\n",
    "        x = torch.sigmoid(y_pred).float().cpu().numpy()\n",
    "        for j in range(len(labels)):\n",
    "            if len(labels) == 1:\n",
    "                output_dict[labels[j]] = x\n",
    "                pool_dict[labels[j]] = y_pool.float().cpu().numpy()\n",
    "                annot_dict[labels[j]] = y_attn[:lengths[j]].float().cpu().numpy()\n",
    "            else:\n",
    "                output_dict[labels[j]] = x[j]\n",
    "                pool_dict[labels[j]] = y_pool[j].float().cpu().numpy()\n",
    "                annot_dict[labels[j]] = y_attn[j,:lengths[j]].float().cpu().numpy()\n",
    "\n",
    "    output_df = pd.DataFrame(output_dict.items(), columns=['ACC', 'preds'])\n",
    "    annot_df = pd.DataFrame(annot_dict.items(), columns=['ACC', 'pred_annot'])\n",
    "    pool_df = pd.DataFrame(pool_dict.items(), columns=['ACC', 'embeds'])\n",
    "    return output_df.merge(annot_df).merge(pool_df)\n",
    "    \n",
    "def generate_sl_outputs(\n",
    "        model_attrs: ModelAttributes, \n",
    "        datahandler: DataloaderHandler, \n",
    "        thresh_type=\"mcc\", \n",
    "        inner_i=\"1Layer\", \n",
    "        reuse=False):\n",
    "    \n",
    "    threshold_dict = {}\n",
    "        \n",
    "    for outer_i in range(5):\n",
    "        print(\"Generating output for ensemble model\", outer_i)\n",
    "        dataloader, data_df = datahandler.get_partition_dataloader_inner(outer_i)\n",
    "        if not os.path.exists(os.path.join(model_attrs.outputs_save_path, f\"inner_{outer_i}_{inner_i}.pkl\")):\n",
    "            path = f\"{model_attrs.save_path}/{outer_i}_{inner_i}.ckpt\"\n",
    "            model = model_attrs.class_type.load_from_checkpoint(path).to(device).eval()\n",
    "            pred_df = predict_sl_values(dataloader, model)\n",
    "            pred_df.to_pickle(os.path.join(model_attrs.outputs_save_path, f\"inner_{outer_i}_{inner_i}.pkl\"))\n",
    "        else:\n",
    "            pred_df = pd.read_pickle(os.path.join(model_attrs.outputs_save_path, f\"inner_{outer_i}_{inner_i}.pkl\"))\n",
    "\n",
    "        if thresh_type == \"roc\":\n",
    "            thresholds = get_optimal_threshold(pred_df, data_df)\n",
    "        elif thresh_type == \"pr\":\n",
    "            thresholds = get_optimal_threshold_pr(pred_df, data_df)\n",
    "        else:\n",
    "            thresholds = get_optimal_threshold_mcc(pred_df, data_df)\n",
    "        threshold_dict[f\"{outer_i}_{inner_i}\"] = thresholds\n",
    "        \n",
    "        if not os.path.exists(os.path.join(model_attrs.outputs_save_path, f\"{outer_i}_{inner_i}.pkl\")):\n",
    "            dataloader, data_df = datahandler.get_partition_dataloader(outer_i)\n",
    "            output_df = predict_sl_values(dataloader, model)\n",
    "            output_df.to_pickle(os.path.join(model_attrs.outputs_save_path, f\"{outer_i}_{inner_i}.pkl\"))\n",
    "\n",
    "    with open(os.path.join(model_attrs.outputs_save_path, f\"thresholds_sl_{thresh_type}.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(threshold_dict, f)\n",
    "\n",
    "def predict_ss_values(X, model):\n",
    "    X_tensor = torch.tensor(X, device=device).float()\n",
    "    y_preds = torch.sigmoid(model(X_tensor))\n",
    "    return y_preds.detach().cpu().numpy()\n",
    "\n",
    "def generate_ss_outputs(\n",
    "        model_attrs: ModelAttributes, \n",
    "        datahandler: DataloaderHandler, \n",
    "        thresh_type=\"mcc\", \n",
    "        inner_i=\"1Layer\", \n",
    "        reuse=False):\n",
    "    \n",
    "    threshold_dict = {}\n",
    "    if not os.path.exists(f\"{model_attrs.outputs_save_path}\"):\n",
    "        os.makedirs(f\"{model_attrs.outputs_save_path}\")\n",
    "    for outer_i in range(5):\n",
    "        print(\"Generating output for ensemble model\", outer_i)\n",
    "        X_train, y_train, X_test, y_test = datahandler.get_swissprot_ss_xy(model_attrs.outputs_save_path, outer_i)\n",
    "        path = f\"{model_attrs.save_path}/signaltype/{outer_i}.ckpt\"\n",
    "        model = SignalTypeMLP.load_from_checkpoint(path).to(device).eval()\n",
    "        \n",
    "        y_train_preds = predict_ss_values(X_train, model)\n",
    "        thresh = np.zeros((9,))\n",
    "        threshold_dict = {}\n",
    "        #print(\"thresholds\")\n",
    "        for type_i in range(9):\n",
    "            thresh[type_i] = get_best_threshold_mcc(y_train[:, type_i], y_train_preds[:, type_i])\n",
    "            threshold_dict[SS_CATEGORIES[type_i+1]] = thresh[type_i]\n",
    "            #print(SS_CATEGORIES[type_i+1], thresh[type_i])\n",
    "        y_test_preds = predict_ss_values(X_test, model)\n",
    "        pickle.dump(y_test_preds, open(f\"{model_attrs.outputs_save_path}/ss_{outer_i}.pkl\", \"wb\"))\n",
    "\n",
    "    with open(os.path.join(model_attrs.outputs_save_path, f\"thresholds_ss_mcc.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(threshold_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import hamming_loss, matthews_corrcoef, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from src.constants import *\n",
    "from src.utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# taken from https://www.kaggle.com/cpmpml/optimizing-probabilities-for-best-mcc\n",
    "def mcc(tp, tn, fp, fn):\n",
    "    sup = tp * tn - fp * fn\n",
    "    inf = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
    "    if inf==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sup / np.sqrt(inf)\n",
    "        \n",
    "def get_best_threshold_mcc(y_true, y_prob):\n",
    "    idx = np.argsort(y_prob)\n",
    "    y_true_sort = y_true[idx]\n",
    "    n = y_true.shape[0]\n",
    "    nump = 1.0 * np.sum(y_true) # number of positive\n",
    "    numn = n - nump # number of negative\n",
    "    tp = nump\n",
    "    tn = 0.0\n",
    "    fp = numn\n",
    "    fn = 0.0\n",
    "    best_mcc = 0.0\n",
    "    best_id = -1\n",
    "    prev_proba = -1\n",
    "    best_proba = -1\n",
    "    mccs = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        # all items with idx < i are predicted negative while others are predicted positive\n",
    "        # only evaluate mcc when probability changes\n",
    "        proba = y_prob[idx[i]]\n",
    "        if proba != prev_proba:\n",
    "            prev_proba = proba\n",
    "            new_mcc = mcc(tp, tn, fp, fn)\n",
    "            if new_mcc >= best_mcc:\n",
    "                best_mcc = new_mcc\n",
    "                best_id = i\n",
    "                best_proba = proba\n",
    "        mccs[i] = new_mcc\n",
    "        if y_true_sort[i] == 1:\n",
    "            tp -= 1.0\n",
    "            fn += 1.0\n",
    "        else:\n",
    "            fp -= 1.0\n",
    "            tn += 1.0\n",
    "\n",
    "    y_pred = (y_prob >= best_proba).astype(int)\n",
    "    score = matthews_corrcoef(y_true, y_pred)\n",
    "    # print(score, best_mcc)\n",
    "    # plt.plot(mccs)\n",
    "    return best_proba\n",
    "\n",
    "def get_optimal_threshold(output_df, data_df):\n",
    "    test_df = data_df.merge(output_df)\n",
    "    \n",
    "    predictions = np.stack(test_df[\"preds\"].to_numpy())\n",
    "    actuals = np.stack(test_df[\"Target\"].to_numpy())\n",
    "    \n",
    "    optimal_thresholds = np.zeros((11,))\n",
    "    for i in range(11):\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(actuals[:, i], predictions[:, i])\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_thresholds[i] = thresholds[optimal_idx]\n",
    "\n",
    "    return optimal_thresholds\n",
    "\n",
    "def get_optimal_threshold_pr(output_df, data_df):\n",
    "    test_df = data_df.merge(output_df)\n",
    "    \n",
    "    predictions = np.stack(test_df[\"preds\"].to_numpy())\n",
    "    actuals = np.stack(test_df[\"Target\"].to_numpy())\n",
    "    \n",
    "    optimal_thresholds = np.zeros((11,))\n",
    "    for i in range(11):\n",
    "        pr, re, thresholds = metrics.precision_recall_curve(actuals[:, i], predictions[:, i])\n",
    "        fscores = (2 * pr * re) / (pr + re)\n",
    "        optimal_idx = np.argmax(fscores)\n",
    "        optimal_thresholds[i] = thresholds[optimal_idx]\n",
    "\n",
    "    return optimal_thresholds\n",
    "\n",
    "def get_optimal_threshold_mcc(output_df, data_df):\n",
    "    test_df = data_df.merge(output_df)\n",
    "    \n",
    "    predictions = np.stack(test_df[\"preds\"].to_numpy())\n",
    "    actuals = np.stack(test_df[\"Target\"].to_numpy())\n",
    "    \n",
    "    optimal_thresholds = np.zeros((11,))\n",
    "    for i in range(11):\n",
    "        optimal_thresholds[i] = get_best_threshold_mcc(actuals[:, i], predictions[:, i])\n",
    "\n",
    "    return optimal_thresholds\n",
    "\n",
    "def calculate_sl_metrics_fold(test_df, thresholds):\n",
    "    print(\"Computing fold\")\n",
    "    predictions = np.stack(test_df[\"preds\"].to_numpy())\n",
    "    outputs = predictions>thresholds\n",
    "    actuals = np.stack(test_df[\"Target\"].to_numpy())\n",
    "\n",
    "    ypred_membrane = outputs[:, 0]\n",
    "    ypred_subloc = outputs[:,1:]\n",
    "    y_membrane = actuals[:, 0]\n",
    "    y_subloc = actuals[:,1:]\n",
    "\n",
    "    metrics_dict = {}\n",
    "\n",
    "    metrics_dict[\"NumLabels\"] = y_subloc.sum(1).mean()\n",
    "    metrics_dict[\"NumLabelsTest\"] = ypred_subloc.sum(1).mean()\n",
    "    metrics_dict[\"ACC_membrane\"] = (ypred_membrane == y_membrane).mean()\n",
    "    metrics_dict[\"MCC_membrane\"] = matthews_corrcoef(y_membrane, ypred_membrane)\n",
    "    metrics_dict[\"ACC_subloc\"] = (np.all((ypred_subloc == y_subloc), axis=1)).mean()\n",
    "    metrics_dict[\"HammLoss_subloc\"] = 1-hamming_loss(y_subloc, ypred_subloc)\n",
    "    metrics_dict[\"Jaccard_subloc\"] = jaccard_score(y_subloc, ypred_subloc, average=\"samples\")\n",
    "    metrics_dict[\"MicroF1_subloc\"] = f1_score(y_subloc, ypred_subloc, average=\"micro\")\n",
    "    metrics_dict[\"MacroF1_subloc\"] = f1_score(y_subloc, ypred_subloc, average=\"macro\")\n",
    "    for i in range(10):\n",
    "      metrics_dict[f\"{CATEGORIES[1+i]}\"] = matthews_corrcoef(y_subloc[:,i], ypred_subloc[:,i])\n",
    "\n",
    "    # for i in range(10):\n",
    "    #    metrics_dict[f\"{categories[1+i]}\"] = roc_auc_score(y_subloc[:,i], predictions[:,i+1])\n",
    "    return metrics_dict\n",
    "\n",
    "def calculate_sl_metrics(model_attrs: ModelAttributes, datahandler: DataloaderHandler, thresh_type=\"mcc\", inner_i=\"1Layer\"):\n",
    "    with open(os.path.join(model_attrs.outputs_save_path, f\"thresholds_sl_{thresh_type}.pkl\"), \"rb\") as f:\n",
    "        threshold_dict = pickle.load(f)\n",
    "    print(np.array(list(threshold_dict.values())).mean(0))\n",
    "    metrics_dict_list = {}\n",
    "    full_data_df = []\n",
    "    for outer_i in range(5):\n",
    "        data_df = datahandler.get_partition(outer_i)\n",
    "        output_df = pd.read_pickle(os.path.join(model_attrs.outputs_save_path, f\"{outer_i}_{inner_i}.pkl\"))\n",
    "        data_df = data_df.merge(output_df)\n",
    "        full_data_df.append(data_df)\n",
    "        threshold = threshold_dict[f\"{outer_i}_{inner_i}\"]\n",
    "        metrics_dict = calculate_sl_metrics_fold(data_df, threshold)\n",
    "        for k in metrics_dict:\n",
    "            metrics_dict_list.setdefault(k, []).append(metrics_dict[k])\n",
    "\n",
    "    output_dict = {}\n",
    "    for k in metrics_dict_list:\n",
    "        output_dict[k] = [f\"{round(np.array(metrics_dict_list[k]).mean(), 2):.2f} pm {round(np.array(metrics_dict_list[k]).std(), 2):.2f}\"]\n",
    "\n",
    "    print(pd.DataFrame(output_dict).to_latex())\n",
    "    for k in metrics_dict_list:\n",
    "        print(\"{0:21s} : {1}\".format(k, f\"{round(np.array(metrics_dict_list[k]).mean(), 2):.2f} + {round(np.array(metrics_dict_list[k]).std(), 2):.2f}\"))\n",
    "    for k in metrics_dict_list:\n",
    "        print(\"{0}\".format(f\"{round(np.array(metrics_dict_list[k]).mean(), 2):.2f} + {round(np.array(metrics_dict_list[k]).std(), 2):.2f}\"))\n",
    "\n",
    "\n",
    "def calculate_ss_metrics_fold(y_test, y_test_preds, thresh):\n",
    "    y_preds = y_test_preds > thresh\n",
    "\n",
    "    metrics_dict = {}\n",
    "\n",
    "    metrics_dict[\"microF1\"] = f1_score(y_test, y_preds, average=\"micro\")\n",
    "    metrics_dict[\"macroF1\"] = f1_score(y_test, y_preds, average=\"macro\")\n",
    "    metrics_dict[\"accuracy\"] = (np.all((y_preds == y_test), axis=1)).mean()\n",
    "\n",
    "    for j in range(len(SS_CATEGORIES)-1):\n",
    "        metrics_dict[f\"{SS_CATEGORIES[j+1]}\"]  = matthews_corrcoef(y_preds[:, j],y_test[:, j])\n",
    "\n",
    "    return metrics_dict\n",
    "\n",
    "def calculate_ss_metrics(model_attrs: ModelAttributes, datahandler: DataloaderHandler, thresh_type=\"mcc\"):\n",
    "    with open(os.path.join(model_attrs.outputs_save_path, f\"thresholds_ss_{thresh_type}.pkl\"), \"rb\") as f:\n",
    "        threshold_dict = pickle.load(f)\n",
    "    # print(np.array(list(threshold_dict.values())).mean(0))\n",
    "    metrics_dict_list = {}\n",
    "    thresh = np.array([threshold_dict[k] for k in SS_CATEGORIES[1:]])\n",
    "    \n",
    "    for outer_i in range(5):\n",
    "        _,_,_, y_test = datahandler.get_swissprot_ss_xy(model_attrs.outputs_save_path, outer_i)\n",
    "        y_test_preds = pickle.load(open(f\"{model_attrs.outputs_save_path}/ss_{outer_i}.pkl\", \"rb\"))\n",
    "        metrics_dict = calculate_ss_metrics_fold(y_test, y_test_preds, thresh)\n",
    "        for k in metrics_dict:\n",
    "            metrics_dict_list.setdefault(k, []).append(metrics_dict[k])\n",
    "\n",
    "    output_dict = {}\n",
    "    for k in metrics_dict_list:\n",
    "        output_dict[k] = [f\"{round(np.array(metrics_dict_list[k]).mean(), 2):.2f} pm {round(np.array(metrics_dict_list[k]).std(), 2):.2f}\"]\n",
    "    print(pd.DataFrame(output_dict).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from .attr_prior import *\n",
    "from src.constants import *\n",
    "\n",
    "\n",
    "pos_weights_bce = torch.tensor([1,1,1,3,2.3,4,9.5,4.5,6.6,7.7,32])\n",
    "def focal_loss(input, target, gamma=1):\n",
    "    bceloss = F.binary_cross_entropy_with_logits(input, target, pos_weight=pos_weights_bce.to(input.device), reduction=\"none\")\n",
    "    logpt = -F.binary_cross_entropy_with_logits(input, target, reduction=\"none\")\n",
    "    pt = torch.exp(logpt)\n",
    "    # compute the loss\n",
    "    focal_loss = ( (1-pt) ** gamma ) * bceloss\n",
    "    return focal_loss.mean()\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "      def __init__(self, hidden_dim, n_heads):\n",
    "          super(AttentionHead, self).__init__()\n",
    "          self.n_heads = n_heads\n",
    "          self.hidden_dim = hidden_dim\n",
    "          self.preattn_ln = nn.LayerNorm(hidden_dim//n_heads)\n",
    "          self.Q = nn.Linear(hidden_dim//n_heads, n_heads, bias=False)\n",
    "          torch.nn.init.normal_(self.Q.weight, mean=0.0, std=1/(hidden_dim//n_heads))\n",
    "\n",
    "      def forward(self, x, np_mask, lengths):\n",
    "          # input (batch, seq_len, embed)\n",
    "          n_heads = self.n_heads\n",
    "          hidden_dim = self.hidden_dim\n",
    "          x = x.view(x.size(0), x.size(1), n_heads, hidden_dim//n_heads)\n",
    "          x = self.preattn_ln(x)\n",
    "          mul = (x * \\\n",
    "                self.Q.weight.view(1, 1, n_heads, hidden_dim//n_heads)).sum(-1) \\\n",
    "                #* np.sqrt(5)\n",
    "                #/ np.sqrt(hidden_dim//n_heads)\n",
    "          mul_score_list = []\n",
    "          for i in range(mul.size(0)):\n",
    "              # (1, L) -> (1, 1, L) -> (1, L) -> (1, L, 1)\n",
    "              mul_score_list.append(F.pad(smooth_tensor_1d(mul[i, :lengths[i], 0].unsqueeze(0), 2).unsqueeze(0),(0, mul.size(1)-lengths[i]),\"constant\").squeeze(0))\n",
    "          \n",
    "          mul = torch.cat(mul_score_list, dim=0).unsqueeze(-1)\n",
    "          mul = mul.masked_fill(~np_mask.unsqueeze(-1), float(\"-inf\"))\n",
    "          \n",
    "          attns = F.softmax(mul, dim=1) # (b, l, nh)\n",
    "          x = (x * attns.unsqueeze(-1)).sum(1)\n",
    "          x = x.view(x.size(0), -1)\n",
    "          return x, attns.squeeze(2)\n",
    "\n",
    "class BaseModel(pl.LightningModule):\n",
    "    def __init__(self, embed_dim) -> None:\n",
    "        super().__init__()\n",
    "       \n",
    "        self.initial_ln = nn.LayerNorm(embed_dim)\n",
    "        self.lin = nn.Linear(embed_dim, 256)\n",
    "        self.attn_head = AttentionHead(256, 1)\n",
    "        self.clf_head = nn.Linear(256, 11)\n",
    "        self.kld = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        self.lr = 1e-3\n",
    "\n",
    "    def forward(self, embedding, lens, non_mask):\n",
    "        x = self.initial_ln(embedding)\n",
    "        x = self.lin(x)\n",
    "        x_pool, x_attns = self.attn_head(x, non_mask, lens)\n",
    "        x_pred = self.clf_head(x_pool)\n",
    "        #print(x_pred, x_attns)\n",
    "        return x_pred, x_attns\n",
    "\n",
    "    def predict(self, embedding, lens, non_mask):\n",
    "        x = self.initial_ln(embedding)\n",
    "        x = self.lin(x)\n",
    "        x_pool, x_attns = self.attn_head(x, non_mask, lens)\n",
    "        x_pred = self.clf_head(x_pool)\n",
    "        #print(x_pred, x_attns)\n",
    "        return x_pred, x_pool, x_attns\n",
    "    \n",
    "    def attn_reg_loss(self, y_true, y_attn, y_tags, lengths, n):\n",
    "        loss = 0\n",
    "        count = 0\n",
    "        reg_loss = 0\n",
    "        for i in range(y_true.size(0)):\n",
    "            reg_loss += fourier_att_prior_loss_dct(\n",
    "                  F.pad(y_attn[i, :lengths[i]].unsqueeze(0).unsqueeze(0), (8,8),\"replicate\").squeeze(1),\n",
    "                  lengths[i]//6,\n",
    "                  0.2, 3)\n",
    "        reg_loss = reg_loss / y_true.size(0)\n",
    "        kld_loss = 0\n",
    "        kld_count = 0\n",
    "        for i in range(y_true.size(0)):\n",
    "            if y_tags[i].sum() > 0:         \n",
    "                for j in range(9):\n",
    "                    if (j+1) in y_tags[i]:\n",
    "                        pos_tar = (y_tags[i]==(j+1)).float()\n",
    "                        kld_count += 1\n",
    "                        kld_loss += pos_weights_annot[j] * self.kld(\n",
    "                            torch.log(y_attn[i, :+lengths[i]].unsqueeze(0)), \n",
    "                            pos_tar[:lengths[i]].unsqueeze(0) / pos_tar[:lengths[i]].sum().unsqueeze(0))\n",
    "        return reg_loss, kld_loss / torch.tensor(kld_count + 1e-5), kld_count\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        grouped_parameters = [\n",
    "            {\"params\": [p for n, p in self.named_parameters()]}\n",
    "        ]\n",
    "        optimizer = torch.optim.AdamW(grouped_parameters, lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                    optimizer, mode=\"min\", factor=0.1, patience=1,\n",
    "                    min_lr=1e-5)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"bce_loss\"\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #self.unfreeze()\n",
    "        x, l, n, y, y_tags, _ = batch\n",
    "        y_pred, y_attns =  self.forward(x, l, n)\n",
    "        reg_loss, seq_loss, seq_count = self.attn_reg_loss(y, y_attns, y_tags, l, n)\n",
    "        bce_loss = focal_loss(y_pred, y)\n",
    "        loss = bce_loss + SUP_LOSS_MULT * seq_loss + REG_LOSS_MULT * reg_loss\n",
    "        self.log('train_loss_batch', loss, on_epoch=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        #self.unfreeze()\n",
    "        x, l, n, y, y_tags, _ = batch\n",
    "        y_pred, y_attns =  self.forward(x, l, n)\n",
    "        reg_loss, seq_loss, seq_count = self.attn_reg_loss(y, y_attns, y_tags, l, n)\n",
    "        bce_loss = focal_loss(y_pred, y)\n",
    "        loss = bce_loss + SUP_LOSS_MULT * seq_loss + REG_LOSS_MULT * reg_loss\n",
    "        self.log('val_loss_batch', loss, on_epoch=True)\n",
    "        self.log('bce_loss', bce_loss, on_epoch=True)\n",
    "        return {'loss': loss, \n",
    "                'seq_loss': seq_loss,\n",
    "                'reg_loss': reg_loss,\n",
    "                'bce_loss': bce_loss,\n",
    "                'seq_count': seq_count}\n",
    "    \n",
    "\n",
    "class ProtT5Frozen(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__(1024)\n",
    "\n",
    "class ESM1bFrozen(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__(1280)\n",
    "        \n",
    "\n",
    "pos_weights_annot = torch.tensor([0.23, 0.92, 0.98, 2.63, 5.64, 1.60, 2.37, 1.87, 2.03])\n",
    "class SignalTypeMLP(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.Linear(267, 32)\n",
    "        self.ln2 = nn.Linear(32, 9)\n",
    "        self.lr = 1e-3\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.Tanh()(self.ln1(x))\n",
    "        x = self.ln2(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        grouped_parameters = [\n",
    "            {\"params\": [p for n, p in self.named_parameters()], 'lr': self.lr},\n",
    "        ]\n",
    "        optimizer = torch.optim.AdamW(grouped_parameters, lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #self.unfreeze()\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = nn.BCEWithLogitsLoss(pos_weight=pos_weights_annot.to(y_pred.device))(y_pred, y)\n",
    "        self.log('train_loss_batch', loss, on_epoch=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        #self.freeze()\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = nn.BCEWithLogitsLoss(pos_weight=pos_weights_annot.to(y_pred.device))(y_pred, y)\n",
    "        self.log('val_loss', loss, on_epoch=True)\n",
    "        return {'loss': loss}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import *\n",
    "from src.data import DataloaderHandler\n",
    "import pickle\n",
    "from transformers import T5EncoderModel, T5Tokenizer, logging\n",
    "import os\n",
    "class ModelAttributes:\n",
    "    def __init__(self, \n",
    "                 model_type: str,\n",
    "                 class_type: pl.LightningModule, \n",
    "                 alphabet, \n",
    "                 embedding_file: str, \n",
    "                 save_path: str,\n",
    "                 outputs_save_path: str,\n",
    "                 clip_len: int,\n",
    "                 embed_len: int) -> None:\n",
    "        self.model_type = model_type\n",
    "        self.class_type = class_type \n",
    "        self.alphabet = alphabet\n",
    "        self.embedding_file = embedding_file\n",
    "        self.save_path = save_path\n",
    "        if not os.path.exists(f\"{self.save_path}\"):\n",
    "            os.makedirs(f\"{self.save_path}\")\n",
    "        self.ss_save_path = os.path.join(self.save_path, \"signaltype\")\n",
    "        if not os.path.exists(f\"{self.ss_save_path}\"):\n",
    "            os.makedirs(f\"{self.ss_save_path}\")\n",
    "\n",
    "        self.outputs_save_path = outputs_save_path\n",
    "\n",
    "        if not os.path.exists(f\"{outputs_save_path}\"):\n",
    "            os.makedirs(f\"{outputs_save_path}\")\n",
    "        self.clip_len = clip_len\n",
    "        self.embed_len = embed_len\n",
    "        \n",
    "\n",
    "def get_train_model_attributes(model_type):\n",
    "    if model_type == FAST:\n",
    "        with open(\"models/ESM1b_alphabet.pkl\", \"rb\") as f:\n",
    "            alphabet = pickle.load(f)\n",
    "        return ModelAttributes(\n",
    "            model_type,\n",
    "            ESM1bFrozen,\n",
    "            alphabet,\n",
    "            EMBEDDINGS[FAST][\"embeds\"],\n",
    "            \"models/models_esm1b\",\n",
    "            \"outputs/esm1b/\",\n",
    "            1022,\n",
    "            1280\n",
    "        )\n",
    "    elif model_type == ACCURATE:\n",
    "        alphabet = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", do_lower_case=False )\n",
    "        \n",
    "        return ModelAttributes(\n",
    "            model_type,\n",
    "            ProtT5Frozen,\n",
    "            alphabet,\n",
    "            EMBEDDINGS[ACCURATE][\"embeds\"],            \n",
    "            \"models/models_prott5\",\n",
    "            \"outputs/prott5/\",\n",
    "            4000,\n",
    "            1024\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"wrong model type provided expected Fast,Accurate got\", model_type)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from src.constants import * \n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.progress import ProgressBar\n",
    "import pytorch_lightning as pl\n",
    "from src.model import *\n",
    "from src.data import *\n",
    "from src.utils import *\n",
    "from src.eval_utils import *\n",
    "\n",
    "\n",
    "def train_model(model_attrs: ModelAttributes, datahandler:DataloaderHandler, outer_i: int):\n",
    "    train_dataloader, val_dataloader = datahandler.get_ss_train_val_dataloader(model_attrs.outputs_save_path, outer_i)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_loss',\n",
    "        dirpath=model_attrs.ss_save_path,\n",
    "        filename= f\"{outer_i}\",\n",
    "        save_top_k=1,\n",
    "        every_n_epochs=1,\n",
    "        save_last=False,\n",
    "        save_weights_only=True\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "         monitor='val_loss',\n",
    "         patience=5, \n",
    "         mode='min'\n",
    "    )\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = pl.Trainer(max_epochs=500, \n",
    "                        default_root_dir=model_attrs.ss_save_path + f\"/{outer_i}\",\n",
    "                        check_val_every_n_epoch = 1,\n",
    "                        callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                        )\n",
    "                        # precision=16,\n",
    "                        # gpus=1)\n",
    "                        #tpu_cores=8)\n",
    "    clf = SignalTypeMLP()\n",
    "    print(f\"Training clf {outer_i}\")\n",
    "    trainer.fit(clf, train_dataloader, val_dataloader)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"-m\",\"--model\", \n",
    "        default=\"Fast\",\n",
    "        choices=['Accurate', 'Fast'],\n",
    "        type=str,\n",
    "        help=\"Model to use.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    model_attrs = get_train_model_attributes(model_type=args.model)\n",
    "    datahandler = DataloaderHandler(\n",
    "        clip_len=model_attrs.clip_len, \n",
    "        alphabet=model_attrs.alphabet, \n",
    "        embedding_file=model_attrs.embedding_file,\n",
    "        embed_len=model_attrs.embed_len\n",
    "    )\n",
    "\n",
    "    print(\"Training sorting signal type prediction models\")\n",
    "    for i in range(0, 5):\n",
    "        print(f\"Training model {i+1} / 5\")\n",
    "        if not os.path.exists(os.path.join(model_attrs.save_path, f\"signaltype/{i}.ckpt\")):\n",
    "            train_model(model_attrs, datahandler, i)\n",
    "    \n",
    "    print(\"Finished training sorting signal type prediction models\")\n",
    "\n",
    "    print(\"Using trained models to generate outputs of signal prediction\")\n",
    "    generate_ss_outputs(model_attrs=model_attrs, datahandler=datahandler)\n",
    "    print(\"Generated outputs!\")\n",
    "\n",
    "    print(\"Computing sorting signal type prediction performance on swissprot CV dataset\")\n",
    "    calculate_ss_metrics(model_attrs=model_attrs, datahandler=datahandler)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
